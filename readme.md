# Materials for the workshop "A Practical Introduction to Transformers"

This repository contains the Jupyter notebooks for the [COMPTEXT 2023](https://www.comptextconference.org/)
tutorial "A Practical Introduction to Transformers: Train Your Own BERT in 2 Hours" 
by [Moritz Laurer](https://www.linkedin.com/in/moritz-laurer) on 11.05.2023.

To run the Jupyter notebooks (.ipynb files) open them here on GitHub
and then click the `Open in Colab` button at the top of the notebook. This will open the notebook
in Google Colab, where you can run the code on free cloud hardware (CPUs or GPUs). 


**Tutorial abstract:** 

While Transformer models like BERT are becoming more popular in the social sciences, 
there is a persistent misconception that they are very complicated to use. 
This workshop will demonstrate that this is not the case anymore. There are amazing 
open-source packages like Hugging Face Transformers that enable anyone with some 
programming knowledge to use, train and evaluate Transformers. We will start with an 
intuitive introduction to transfer learning and discuss its added value for social science 
use-cases as well as limitations. We will then look at the open-source ecosystem and free 
hardware options to train Transformers. The main part of the course will be an interactive 
session, where we will train and evaluate a Transformer on a typical political science task. 
Parts of the workshop will be in Python, but knowledge of Python is not required. 
Participants without prior knowledge of Python or Transformers are explicitly invited to 
participate. You will leave the workshop with Jupyter notebooks that enable you to 
train your own Transformer with your own data for your future research projects. 






